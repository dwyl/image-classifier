Mix.install([
{:bumblebee, "~> 0.4.2"},
{:exla, "~> 0.6.4"},
{:nx, "~> 0.6.4 "},
{:hnswlib, "~> 0.1.4"}
])

Nx.global_default_backend(EXLA.Backend)

{:ok, index} = HNSWLib.Index.new(_space = :cosine, _dim = 384, _max_elements = 200)
transformer = "sentence-transformers/paraphrase-MiniLM-L6-v2"
{:ok, %{model: _model, params: _params} = model_info} =
      Bumblebee.load_model({:hf, transformer})

{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, transformer})
serving = Bumblebee.Text.TextEmbedding.text_embedding(
      model_info, 
      tokenizer, 
      defn_options: [compiler: EXLA, lazy_transfers: :never]
      #output_pool: :mean_pooling,
      #output_attribute: :hidden_state,
      #embedding_processor: :l2_norm,
    )

%{embedding: data} = Nx.Serving.run(serving, "small") |>dbg()
HNSWLib.Index.add_items(index, data)
HNSWLib.Index.get_count(index) |> dbg()

%{embedding: data} = Nx.Serving.run(serving, "tall") |> dbg()
HNSWLib.Index.add_items(index, data)
HNSWLIb.Index.get_count(index) |> dbg()

%{embedding: data} = Nx.Serving.run(serving, "high")
{:ok, labels, distances} = HNSWLib.Index.knn_query(index, data, k: 1) |> dbg()
idx = Nx.to_flat_list(labels[0])
{:ok, dt} = HNSWLib.Index.get_items(index, idx)
Nx.stack(Enum.map(dt, fn d -> Nx.from_binary(d, :f32) end))

defmodule Embedding do
  use GenServer
  @indexes "indexes.bin"

  def start_link(norm) do
    GenServer.start_link(__MODULE__, norm, name: __MODULE__)
  end

  # upload or create a new index file
  def init(norm) do
    space = norm

    {:ok, index} =
      case File.exists?(@indexes) do
        false ->
          HNSWLib.Index.new(_space = space, _dim = 384, _max_elements = 200)

        true ->
          HNSWLib.Index.load_index(space, 384, @indexes)
      end

    model_info = nil
    tokenizer = nil
    {:ok, {model_info, tokenizer, index}, {:continue, :load}}
  end

  def handle_continue(:load, {_, _, index}) do
    transformer = "sentence-transformers/paraphrase-MiniLM-L6-v2"

    {:ok, %{model: _model, params: _params} = model_info} =
      Bumblebee.load_model({:hf, transformer})

    {:ok, tokenizer} =
      Bumblebee.load_tokenizer({:hf, transformer})

    {:noreply, {model_info, tokenizer, index}}
  end

  def serve() do
    GenServer.call(__MODULE__, :serve)
  end

  def get_count do
    GenServer.call(__MODULE__, :get_count)
  end

  def get_index do
    GenServer.call(__MODULE__, :get_index)
  end

  def handle_call(:serve, _from, {model_info, tokenizer, index} = state) do
    serving = Bumblebee.Text.TextEmbedding.text_embedding(
      model_info, 
      tokenizer, 
      output_pool: :mean_pooling,
      output_attribute: :hidden_state,
      embedding_processor: :l2_norm,
      defn_options: [compiler: EXLA, lazy_transfers: :never]
    )
    {:reply, {serving, index}, state}
  end

  def handle_call(:get_count, _, {_, _, index} = state) do
    {:ok, count} = HNSWLib.Index.get_current_count(index)
    {:reply, count, state}
  end

  def handle_call(:get_index, _, {_, _, index} = state) do
    {:reply, index, state}
  end
end

{:ok, pid} = GenServer.start_link(Embedding, :l2)

{serving, index} = GenServer.call(pid, :serve)

%{embedding: data} = Nx.Serving.run(serving, "small") |>dbg()
HNSWLib.Index.add_items(index, data)
GenServer.call(pid, :get_count) |> dbg()

%{embedding: data} = Nx.Serving.run(serving, "tall") |> dbg()
HNSWLib.Index.add_items(index, data)
GenServer.call(pid, :get_count) |> dbg()

%{embedding: data3} = Nx.Serving.run(serving, "high")
{:ok, labels, distances} = HNSWLib.Index.knn_query(index, data, k: 1) |> dbg()
idx = Nx.to_flat_list(labels[0])
{:ok, dt} = HNSWLib.Index.get_items(index, idx)
Nx.stack(Enum.map(dt, fn d -> Nx.from_binary(d, :f32) end))